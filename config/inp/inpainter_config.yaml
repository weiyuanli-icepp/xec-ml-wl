# ===================================================
# Inpainter (Dead Channel Recovery) Configuration
# ===================================================

# === Data Configuration ===
data:
  train_path: "~/meghome/xec-ml-wl/data/E52.8_AngUni_PosSQ/large_train.root"
  val_path: "~/meghome/xec-ml-wl/data/E52.8_AngUni_PosSQ/large_val.root"
  tree_name: "tree"
  batch_size: 1024
  chunksize: 256000
  num_workers: 1
  num_threads: 4
  npho_branch: "npho"        # Input branch for photon counts (or "npho")
  time_branch: "relative_time"        # Input branch for timing (or "time")
  log_invalid_npho: true              # Log warning when invalid npho values are detected

# === Input Normalization ===
# Must match MAE pretraining normalization
normalization:
  npho_scale: 1000
  npho_scale2: 4.08
  time_scale: 1.14e-7
  time_shift: -0.46
  sentinel_value: -1.0
  # Normalization scheme for npho:
  #   "log1p" (default) - log1p(x/scale)/scale2, good for wide dynamic range
  #   "anscombe" - 2*sqrt(x + 3/8), variance stabilization for Poisson data
  #   "sqrt" - sqrt(x)/sqrt(scale), simpler variance stabilization
  #   "linear" - x/scale, no transform (baseline)
  npho_scheme: "log1p"

# === Model Configuration ===
model:
  outer_mode: "finegrid"            # Must match MAE encoder config
  outer_fine_pool: null             # Must match MAE encoder config
  mask_ratio: 0.05                  # Realistic dead channel density (1-10%)
  # DEPRECATED: delete this line. Use training.time.mask_ratio_scale instead.
  time_mask_ratio_scale: 1.0        # Scale factor for masking valid-time sensors (>1.0 to prefer masking valid-time)
  freeze_encoder: false             # Freeze encoder, train only inpainting heads
  use_local_context: true           # Use local neighbor context for inpainting (disable for ablation)
  predict_channels: ["npho"]           # Output channels to predict: ["npho"] or ["npho", "time"]
                                      # Use ["npho"] for faster training when time prediction is not needed
  use_masked_attention: false          # Use attention-based heads that predict only at masked positions
  # === Cross-Attention Unified Head ===
  # Set head_type to "cross_attention" to use a single unified head that:
  # - Queries all 6 latent tokens via cross-attention (global context)
  # - Uses cross-face k-nearest neighbors by 3D distance (local context)
  # - Embeds sensor 3D positions via sinusoidal encoding
  # - Embeds face IDs (0-5) to learn SiPM/PMT scale differences
  head_type: "per_face"               # "per_face" or "cross_attention"
  # sensor_positions_file: "lib/sensor_positions.txt"  # Required for cross_attention
  # cross_attn_k: 16                  # Number of KNN neighbors for local attention
  # cross_attn_hidden: 64             # Hidden dimension for local attention
  # cross_attn_latent_dim: 128        # Projection dimension for latent cross-attention
  # cross_attn_pos_dim: 96            # Sinusoidal position encoding dimension

# === Training Configuration ===
training:
  # mae_checkpoint: "artifacts/mae/mae_checkpoint_best.pth"  # Path to pretrained MAE
  mae_checkpoint: null              # null = no pretrained MAE
  epochs: 50
  lr: 1.0e-4
  lr_scheduler: "cosine"            # "cosine" or null
  lr_min: 1.0e-6
  warmup_epochs: 3
  weight_decay: 1.0e-4
  loss_fn: "smooth_l1"              # Options: smooth_l1, mse, l1, huber
  loss_beta: 0.1                    # Beta for smooth_l1/huber (smaller = more sensitive to medium errors)
  npho_weight: 1.0                  # Weight for npho channel loss
  # DEPRECATED: delete this line. Use training.time.weight instead.
  time_weight: 1.0                  # Weight for time channel loss
  grad_clip: 1.0                    # Gradient clipping (0 to disable)
  amp: true                         # Automatic Mixed Precision
  # torch.compile mode options:
  #   "max-autotune" - Maximum optimization, benchmarks many kernel configs (highest memory)
  #   "reduce-overhead" - Lower compilation overhead and memory, good balance
  #   "default" - Basic compilation with minimal overhead
  #   "false" or "none" - Disable compilation, use eager mode (no extra memory)
  compile: "reduce-overhead"
  track_mae_rmse: false              # Compute/log MAE/RMSE metrics (set false to skip)
  grad_accum_steps: 4               # Gradient accumulation steps (effective batch = batch_size * grad_accum_steps)
  track_train_metrics: false         # Track per-face metrics during training (set false to log only total_loss)
  # DEPRECATED: delete this line. Use training.time.npho_threshold instead.
  npho_threshold: 100              # Npho threshold for conditional time loss (null uses default 10.0)
  # DEPRECATED: delete this line. Use training.time.use_npho_weight instead.
  use_npho_time_weight: true        # Weight time loss by sqrt(npho) for chi-square-like weighting
  ema_decay: null                   # EMA decay rate (null to disable, 0.999 typical)
  profile: false                    # Enable training profiler to identify bottlenecks

  # === Npho Loss Weighting ===
  # Weight reconstruction loss by (npho + 1)^alpha to give higher weight to high-photon-count sensors
  npho_loss_weight:
    enabled: false                  # Enable intensity-based loss weighting
    alpha: 0.5                      # Exponent: 0.5 = sqrt, 1.0 = linear

  # === Intensity-based Sample Reweighting ===
  # Reweight samples by total event intensity to balance representation
  intensity_reweighting:
    enabled: false                  # Enable intensity-based sample reweighting
    nbins: 5                        # Number of intensity bins
    target: "uniform"               # Target distribution ("uniform")

# === Checkpointing ===
checkpoint:
  resume_from: null                 # Path to inpainter checkpoint to resume from
  save_dir: "artifacts/inpainter"   # Directory to save checkpoints
  save_interval: 10                 # Save checkpoint every N epochs
  save_predictions: true            # Write ROOT outputs during validation
  new_mlflow_run: false             # Create new MLflow run when resuming (vs continue existing)

# === Distributed Training ===
distributed:
  num_gpus: 1                       # Number of GPUs (1 = single-GPU, >1 = DDP multi-GPU)

# === MLflow ===
mlflow:
  experiment: "inpainting"
  run_name: null                    # null = auto-generate timestamp
